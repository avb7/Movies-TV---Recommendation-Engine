{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE 158 - Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_oPNrnrZes6",
        "colab_type": "text"
      },
      "source": [
        "# CSE 158 Assignment 2\n",
        "This is our shared jupyter notebook\n",
        "\n",
        "Data\n",
        "- Amazon product review dataset (specifically Movies and TV) : userID, productID, rating\n",
        "- Amazon product review dataset (specifically Movies and TV) : userID, productID, rating, review text, time of purchase, and others.\n",
        "\n",
        "Predictive task:\n",
        "- **Purchase prediction** \"Predict whether a user will the user purchase the product or not\"\n",
        "(purchase(userID, product) = true or false)\n",
        "\n",
        "##### Notes:\n",
        "* Note 1: Since the reviews are only for the movies that have been purchased, the dataset is un-balanced. Balanced dataset would have reviews for the un-purchased movies in addition to the reviews for the purchased movies. Therefore, an alternative predictive task may be to predict (1) whether or not a user likes/dislikes a movie or (2) what rating a user would give a movie.\n",
        "\n",
        "*  Note 2: Try Alternative model other than logistic regression: (1) TF-IDF prediction (2) SVM (3) k-means neighbor. Present the results using histograms.\n",
        "\n",
        "* Note 3: Data visualization.\n",
        "\n",
        "* Note 4: Report various error metrics : (1) MSE, (2) Accuracy, (3) BER\n",
        "\n",
        "* Note 5: The dataset in use uses reviews that have at least 5 for each product and for each user. Therefore, we may have higher accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIXxI4q0tXn9",
        "colab_type": "text"
      },
      "source": [
        "# Libraries Used\n",
        "Here's a list of libraries we use in our project. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7obngyJZMmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import scipy.optimize\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import string\n",
        "import random\n",
        "import string\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBSbjm5ZuYpL",
        "colab_type": "code",
        "outputId": "8f32f0e9-c256-412f-bd4b-e9e255d51c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "movie_rating = []\n",
        "with open(\"./Movies_and_TV.csv\") as f:\n",
        "  for l in f:\n",
        "    l = l.rstrip().split(',')\n",
        "    movie_rating.append(l)\n",
        "\n",
        "movie_rating[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6dfffe9cbff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmovie_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Movies_and_TV.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmovie_rating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Movies_and_TV.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mARl2c1EmH_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIa-uJeXEmWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sC5_mQnyb4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = len(movie_rating)\n",
        "\n",
        "X_train = movie_rating[:round(total*0.6)]\n",
        "X_validate = movie_rating[round(total*0.6):round(total*0.8)]\n",
        "X_test = movie_rating[round(total*0.8):]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG8eZ4svGh3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[0:50000]\n",
        "X_validate = X_validate[:20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuoJR8Rijubb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFHehFve97uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "productreview_count = dict()\n",
        "for review in movie_rating:\n",
        "  productID = review[0]\n",
        "  if productID in productreview_count.keys():\n",
        "    count = productreview_count[productID]\n",
        "    productreview_count[productID] = count + 1\n",
        "  else:\n",
        "    productreview_count[productID] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekptk-Xn-oPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mostFrequent = [(productreview_count[x], x) for x in productreview_count.keys()]\n",
        "mostFrequent.sort()\n",
        "mostFrequent.reverse()\n",
        "\n",
        "mostFrequent1000 = []\n",
        "for i in mostFrequent[:1000]:\n",
        "    mostFrequent1000.append(i[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5oVzwZCtX1l",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions\n",
        "Here's our collection of helper functions that we use in our project. We have the following functions implemented below:\n",
        "- ***Jaccard(s1, s2)*** - computes the Jaccard similarity between two sets \n",
        "- ***printBERandAccuracy(predictions, y)*** - prints the Balanced Rate Error and the Accuracy of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVoEjVaa3QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Jaccard(s1, s2):\n",
        "    ''' Computes the Jaccard similarity between two sets\n",
        "    '''\n",
        "    numer = len(s1.intersection(s2))\n",
        "    denom = len(s1.union(s2))\n",
        "    if denom > 0:\n",
        "        return numer/denom\n",
        "    return 0\n",
        "    \n",
        "def printBERandAccuracy(predictions, y):\n",
        "    ''' Calculates and Prints BER and Accuracy \n",
        "        for given Predictions and y. \n",
        "        Used as helper function for all homework questions. \n",
        "    '''\n",
        "    # Calculating accuracy and balanced error rate \n",
        "    index = 0\n",
        "    correctCount = 0\n",
        "    falsePositives = 0\n",
        "    falseNegatives = 0\n",
        "    labeledPositives = 0\n",
        "    labeledNegatives = 0\n",
        "    \n",
        "    for p in predictions:\n",
        "        #checking correctCount\n",
        "        if p==y[index]:\n",
        "            correctCount = correctCount + 1\n",
        "        \n",
        "        #checking false positives \n",
        "        if p and not y[index]:\n",
        "            falsePositives = falsePositives+1\n",
        "        \n",
        "        #checking false negatves \n",
        "        if not p and y[index]:\n",
        "            falseNegatives = falseNegatives + 1\n",
        "        \n",
        "        #labeled positive\n",
        "        if y[index]:\n",
        "            labeledPositives = labeledPositives + 1\n",
        "        \n",
        "        #labeled positive\n",
        "        if not y[index]:\n",
        "            labeledNegatives = labeledNegatives + 1\n",
        "    \n",
        "        index = index + 1\n",
        "    \n",
        "    #calculate accuracy \n",
        "    accuracy = correctCount/len(predictions)\n",
        "\n",
        "    #calculate balanced error rate \n",
        "    fpr = falsePositives/labeledNegatives\n",
        "    fnr = falseNegatives/labeledPositives\n",
        "    ber = 0.5*(fpr+fnr)\n",
        "\n",
        "    print(\"Balanced Error Rate: \"+ str(ber))\n",
        "    print(\"Accuracy: \"+ str(accuracy))\n",
        "    \n",
        "    return ber"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S6UfAPszjxV",
        "colab_type": "text"
      },
      "source": [
        "# Useful Information\n",
        "\n",
        "- userSet\n",
        "- productSet \n",
        "- purchasedSet\n",
        "- notPurchasedSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiWdfPGjzTSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "userSet = set()\n",
        "productSet = set()\n",
        "purchasedSet = set()\n",
        "\n",
        "notPurchasedSet_train = set()\n",
        "notPurchasedSet_validate = set()\n",
        "notPurchasedSet_test = set()\n",
        "\n",
        "for p, u, r in movie_rating:\n",
        "  productSet.add(p)\n",
        "  userSet.add(u)\n",
        "  purchasedSet.add((u, p))\n",
        "\n",
        "listUserSet = list(userSet)\n",
        "listProductSet = list(productSet)\n",
        "\n",
        "# for train\n",
        "y_train = [] \n",
        "for i in range(len(X_train)):\n",
        "  y_train.append(1)\n",
        "\n",
        "# for validation\n",
        "y_validate = [] \n",
        "for i in range(len(X_validate)):\n",
        "  y_validate.append(1)\n",
        "\n",
        "# for test \n",
        "y_test = []\n",
        "for i in range(len(X_test)):\n",
        "  y_test.append(1)\n",
        "\n",
        "#train\n",
        "for p, u, r in X_train:\n",
        "  product = random.choice(listProductSet)\n",
        "  if (u,product) in purchasedSet or (u, product) in notPurchasedSet_train: continue\n",
        "  notPurchasedSet_train.add((u, product))\n",
        "  y_train.append(0)\n",
        "\n",
        "#validate\n",
        "for p, u, r in X_validate:\n",
        "  product = random.choice(listProductSet)\n",
        "  if (u,product) in purchasedSet or (u, product) in notPurchasedSet_validate: continue\n",
        "  notPurchasedSet_validate.add((u, product))\n",
        "  y_validate.append(0)\n",
        "  \n",
        "#train \n",
        "for p, u, r in X_test:\n",
        "  product = random.choice(listProductSet)\n",
        "  if (u,product) in purchasedSet or (u, product) in notPurchasedSet_test: continue\n",
        "  notPurchasedSet_test.add((u, product))\n",
        "  y_test.append(0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzfxgKr1MoPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA3ypzafMq-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(X_train) + len(notPurchasedSet_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKaPj1ePvmCm",
        "colab_type": "code",
        "outputId": "3771268e-4236-4af5-a1d1-de2099b6e13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#basic stats \n",
        "\n",
        "print(len(movie_rating))\n",
        "print(len(productSet))\n",
        "print(len(userSet))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5747dd806c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproductSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'movie_rating' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqRLsA9v1HuR",
        "colab_type": "text"
      },
      "source": [
        "# Model - Logistic Regression (Training)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doOQZRAo2DAt",
        "colab_type": "code",
        "outputId": "fbf84a59-e651-4b22-f668-217cf04c5cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "featureMatrix_train = []\n",
        "\n",
        "#train processable set \n",
        "purchasedTrain = []\n",
        "for d in X_train:\n",
        "  p = d[0]\n",
        "  u = d[1]\n",
        "  purchasedTrain.append((u, p))\n",
        "\n",
        "\n",
        "# Building featureMatrix for TRAINING  \n",
        "ratingsPerUser = defaultdict(list)\n",
        "ratingsPerItem = defaultdict(list)\n",
        "for p,u,r in X_train:\n",
        "    ratingsPerUser[u].append((p,r))\n",
        "    ratingsPerItem[p].append((u,r))\n",
        "\n",
        "for (label, sample) in [(1, purchasedTrain), (0, list(notPurchasedSet_train))]:\n",
        "  for (u, p) in sample:\n",
        "    \n",
        "    #user Jaccard \n",
        "    maxSimUser = 0\n",
        "    similar_users = set(ratingsPerItem[p])\n",
        "    for p2, _ in ratingsPerUser[u]:\n",
        "      sim = Jaccard(similar_users, set(ratingsPerItem[p2]))\n",
        "      if sim > maxSimUser:\n",
        "        maxSimUser = sim\n",
        "\n",
        "    #product Jaccard \n",
        "    maxSimProduct = 0\n",
        "    productsUserHasPurchased = set(ratingsPerUser[u])\n",
        "    for u2, _ in ratingsPerItem[p]:\n",
        "      sim = Jaccard(productsUserHasPurchased, set(ratingsPerUser[u2]))\n",
        "      if sim > maxSimProduct:\n",
        "        maxSimProduct = sim \n",
        "\n",
        "    feature1 = 1\n",
        "    feature2 = maxSimUser\n",
        "    feature3 = maxSimProduct\n",
        "    feature4 = len(ratingsPerUser[u])\n",
        "    feature5 = len(ratingsPerItem[p])\n",
        "\n",
        "    featureVector = []\n",
        "    featureVector.append(feature1)\n",
        "    featureVector.append(feature2)\n",
        "    featureVector.append(feature3)\n",
        "    featureVector.append(feature4)\n",
        "    featureVector.append(feature5)\n",
        "\n",
        "    featureMatrix_train.append(featureVector)\n",
        "\n",
        "\n",
        "featureMatrix_train = np.array(featureMatrix_train)\n",
        "\n",
        "model = linear_model.LogisticRegression()\n",
        "model.fit(featureMatrix_train, y_train)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-oNim9hMK_2",
        "colab_type": "code",
        "outputId": "5e3b46ff-98a6-47ae-e7c7-cbe22f68717a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_validate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDd9OOh4K5PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FEATURE MATRIX FOR VALIDATE\n",
        "featureMatrix_validate = []\n",
        "\n",
        "#validation processable set \n",
        "purchasedValid = []\n",
        "for d in X_validate:\n",
        "  p = d[0]\n",
        "  u = d[1]\n",
        "  purchasedValid.append((u, p))\n",
        "\n",
        "# Building featureMatrix for TRAINING  \n",
        "ratingsPerUser = defaultdict(list)\n",
        "ratingsPerItem = defaultdict(list)\n",
        "for p,u,r in X_validate:\n",
        "    ratingsPerUser[u].append((p,r))\n",
        "    ratingsPerItem[p].append((u,r))\n",
        "\n",
        "for (label, sample) in [(1, purchasedValid), (0, list(notPurchasedSet_validate))]:\n",
        "  for (u, p) in sample:\n",
        "    \n",
        "    #user Jaccard \n",
        "    maxSimUser = 0\n",
        "    similar_users = set(ratingsPerItem[p])\n",
        "    for p2, _ in ratingsPerUser[u]:\n",
        "      sim = Jaccard(similar_users, set(ratingsPerItem[p2]))\n",
        "      if sim > maxSimUser:\n",
        "        maxSimUser = sim\n",
        "\n",
        "    #product Jaccard \n",
        "    maxSimProduct = 0\n",
        "    productsUserHasPurchased = set(ratingsPerUser[u])\n",
        "    for u2, _ in ratingsPerItem[p]:\n",
        "      sim = Jaccard(productsUserHasPurchased, set(ratingsPerUser[u2]))\n",
        "      if sim > maxSimProduct:\n",
        "        maxSimProduct = sim \n",
        "\n",
        "    feature1 = 1\n",
        "    feature2 = maxSimUser\n",
        "    feature3 = maxSimProduct\n",
        "    feature4 = len(ratingsPerUser[u])\n",
        "    feature5 = len(ratingsPerItem[p])\n",
        "\n",
        "    featureVector = []\n",
        "    featureVector.append(feature1)\n",
        "    featureVector.append(feature2)\n",
        "    featureVector.append(feature3)\n",
        "    featureVector.append(feature4)\n",
        "    featureVector.append(feature5)\n",
        "\n",
        "    featureMatrix_validate.append(featureVector)\n",
        "\n",
        "featureMatrix_validate = np.array(featureMatrix_validate)\n",
        "\n",
        "predictions_validate = model.predict(featureMatrix_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuSi__wV73aC",
        "colab_type": "code",
        "outputId": "d0ef3135-fd7c-41d3-de9c-addd6ae879f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "printBERandAccuracy(predictions_validate, y_validate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced Error Rate: 0.014400025002500249\n",
            "Accuracy: 0.9855992799639982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.014400025002500249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}